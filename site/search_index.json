[["index.html", "Research methods Section 1 Syllabus 1.1 Teaching 1.2 Scoring 1.3 Topics", " Research methods Section 1 Syllabus These course notes include information and study materials on the quantitative part of MS.0825 Research methods course of Agri-Food Business Management Master’s program. 1.1 Teaching Flipped classroom approach is used for teaching. This means that students are expected to learn the methods before meetings. During the meetings we revise the theoretical material, address any questions and apply methods in practice. After meetings students apply the methods on their own datasets. 1.1.1 Schedule Meetings take place on Mondays, Wednesdays and Thursdays at 9 o’clock in the morning. Link to meetings is provided under the course page in Moodle. 1.1.2 Aims After completing the course students should be able to … … understand basic concepts in statistics; … know how to describe data, both numerically and visually; … choose an appropriate method to solve a problem; … use a statistical package for data analysis; … communicate results (interpret, explain, present); … learn about statistical methods individually; … find the courage to apply statistical methods. 1.2 Scoring This part of the course gives 50% of total course points. This 50% consists of 50 points that can be obtained by submitting: feedback on reading material for upcoming meeting (10*1=10 points), and report containing the application of methods learned (10*4=40 points). To gain the 40 points students are required to combine the applications of a method into a report. Participation in meetings does not affect points but meetings are not recorded. 1.2.1 Feedback on reading material Submit your questions or thoughts on given reading material before each meeting in Moodle. Feedback can be either an explanation of something you learned, a question on something you don’t understand, or an answer to another student’s question. Compulsory reading is from two books: Navarro and Foxcroft (2018) and Crawley (2013). 1.2.2 Research project Students are required to create a research report as follows: Choose a data set Apply at least one method from each meeting on this data set Make changes according to feedback Present the results as a written report Submit the report before the end of May. 1.2.2.1 Datasets To apply methods, datasets need to have multiple variables. We mostly learn to explore continuous data but some methods require at least one discrete variable. Students are free to choose a dataset with the requriment that chosen data is different from what other students have chosen. Possible sources for data: Goodle dataset search Kaggle datasets Data hub collections 1.3 Topics We cover some common and traditional statistical methods. Descriptive statistics Hypothesis testing. Comparing categorical variables Comparing numerical variables Analysis of variance Correlation analysis Regression. Ordinary Least Squares Regression. Factors and transformations Regression. Maximum likelihood and binary models Principal component analysis Factor analysis Hierarchical clustering K-means clustering "],["introduction.html", "Section 2 Introduction 2.1 Quantitative methods 2.2 Statistics 2.3 Software 2.4 Data management", " Section 2 Introduction 2.1 Quantitative methods 2.1.1 Quantitative and qualitative methods QuaNTitative QuaLitative Numeric data Semantic data Large-N Small-N, case studies Generalize Explore Measure and test Understand Statistical analysis Interpretation 2.2 Statistics See Navarro and Foxcroft (2018) sections 1.1.1 and 1.5 for a brief introduction. Sections 2.3-2.7 also provide useful background on validity and reliability of statistical methods. Dash (2016) has summarized statistics as follows: Figure 2.1: Flowchart of statistics 2.2.1 Descriptive and inferential statistics Descriptive statistics Inferential statistics Data on entire population Only a sample of a population Simple measures (e.g. mean) Point estimates and intervals Describing Generalizing 2.2.2 Frequentist and bayesian approach to statistics Frequentist Bayesian Traditional Modern What’s the probability of data given some estimate? What’s the probability of an estimate? Prior is not relevant Estimates are conditional on priors Single parametric inference Multiplication of an inference to get a posterior estimate 2.2.3 Statistics and data science, machine learning, artificial intelligence, … Statistics DS, ML, AI, … Less data Big data Clean datasets Untidy data in various formats Traditonal methods Novel methods Mathematics and calculations Programming approach Aim is to explain Aim is to predict 2.3 Software 2.3.1 Commonly used software Spreadsheet vs statistical software Spreadsheet - table management (e.g. Microsoft Excel, Google Sheets, LibreOffice Calc) SPSS - simple GUI-based app with limited functionality R - extensible programming language designed for data analysis Stata - Mostly CLI-based, well suited for econometrics 2.3.2 Jamovi To apply the methods we learn, we use Jamovi. Jamovi is a new “3rd generation” statistical spreadsheet. designed from the ground up to be easy to use, jamovi is a compelling alternative to costly statistical products such as SPSS and SAS. Jamovi is built on top of the R statistical language, giving you access to the best the statistics community has to offer. You can try it online without installing at https://cloud.jamovi.org/. 2.3.3 R language and RStudio This allows us to get under the hood of Jamovi so to speak. R language is based on S language orginating from 1970’s. Developed during 1990’s and became public around 2000. R is a language and environment for statistical computing and graphics. R provides a wide variety of statistical (linear and nonlinear modelling, classical statistical tests, time-series analysis, classification, clustering, …) and graphical techniques, and is highly extensible. 2.4 Data management 2.4.1 Data structure Usually data is stored in 2-dimensonal tables, i.e. data has rows and columns. To apply statistical procedures, most software requires data to be formatted in a conventional way. In this respect it’s useful to follow “tidy data” principle (Wickham 2014): Every column is a variable. Every row is an observation. Every cell is a single value. This is how data should be formatted before running most statistical procedures. One way to tidy a data table is to use the Pivot table feature in a spreadsheet app. 2.4.2 Scales of measurement Scale of measurement determines the procedures that can be applied to the data. The following typology was first published by Stevens (1946). See Navarro and Foxcroft (2018) section 2.2 for a more detailed explanation. Each scale in the table includes also the properties, operations and measures a on previous rows. Scale Property Operations Central tendency Nominal Classification =, ≠ Mode Ordinal Level &gt;, &lt; Median Interval Difference +, − Arithmetic mean Ratio Magnitude ×, / Geometric mean, harmonic mean 2.4.2.1 Nominal scale Nominal variables contain names (i.e. characters, factors or strings) that do not have a natural order. Such data can be summarized only by counting values or determining the mode. 2.4.2.2 Ordinal scale Ordinal variables have the characteristics of nominal variables with the added possibility of naturally ordering these names. As such, ordinal variables can be said to have levels. It’s important to note that an increase of one level to the next is not necessarily numerically equivalent to an increase of another level to the next. Thus, it is not always meaningful to convert these levels to numbers and do calculations on them. 2.4.2.3 Interval scale Interval variables are expressed numerically. While differences between numbers on interval scale are meaningful, there isn’t a natural zero value. Thus, calculations on interval variables is limited to finding differences and division or multiplication of such values is not reasonable. A classic example of an interval variable is temperature. Difference between 5°C and 15°C is 10°C but 15°C is not 3 times warmer than 5°C. 2.4.2.4 Ratio scale Ratio variables are also numeric but have a natural zero value. This means that division and multiplication is meaningful. 2.4.2.5 Binary scale Binary (or dichotomous) variables do not constitute a distinct scale but can be considered as a subgroup of nominal, ordinal or interval variables. Binary variables can only take two values. Many statistical procedures convert or require the conversion of nominal variables to binary for technical reasons (e.g. “dummy” variables). Binary variables are often coded as 0 for false and 1 for true. As such, calculating the sum or mean of binary variables conveys useful information (think why that is!). 2.4.2.6 Continuous or discrete variables In addition to the previous typology, we can also distinguish between continuous and discrete variables. These are well defined by Navarro and Foxcroft (2018, 20): \"A continuous variable is one in which, for any two values that you can think of, it’s always logically possible to have another value in between. A discrete variable is, in effect, a variable that isn’t continuous. For a discrete variable it’s sometimes the case that there’s nothing in the middle.\" 2.4.2.7 Scales in statistical software The difference between ratio and interval variables is only theoretical. Statistical software treats all numbers as numeric variables and does not distinguish between interval and ratio variables. When binary variables are coded so that they only have values 0 and 1, these are also considered numerical. A lot of statistical software (e.g. Jamovi) distinguish only between three types of variables: nominal, ordinal and numeric. "],["descriptive-statistics.html", "Section 3 Descriptive statistics 3.1 Central tendency 3.2 Variability 3.3 Plots", " Section 3 Descriptive statistics Any data analysis should begin with an exploration of the structure of and values in dataset. Description of values should also be part of the reporting of analysis. This can be done using some simple methods. When we use the methods of descriptive statistics, we need to be aware of that we merely describe the dataset at hand. If observations in the data set constitute a sample, we cannot draw any wider conclusions on population using these methods. Below we are thus defining the statistics for populations and not samples. Description of nominal or ordinal variables is simple and limited to just counting unique values and finding the mode and/or median value. But suppose we have variables that contain sequences of numbers. How can we describe these? 3.1 Central tendency A concise way to represent numeric values is expressing the center of values. This can also be understood the typical value or expected value (expectation of \\(x\\), i.e. \\(E(x)\\)). Note that estimating a central tendency is only meaningful if there is a natural center. i.e. the distribution of values is unimodal. See Navarro and Foxcroft (2018) section 4.1. 3.1.1 Mode Mode is simply the most frequent value in a sequence. This statistic can be useful for nominal and ordinal variables but it’s rarely used for numeric variables, especially on a continuous scale. 3.1.2 Median When sequence of values is ordered, the middle value is median. In case there are even number of values (\\(N\\)) in a sequence, median is the average of the two values in the middle. Thus, there are equal number of values above and below the median value. When \\(N\\) is an even number, half of the values are above and half below the median value. 3.1.3 Mean While there are several forms of mean, arithmetic mean is most useful in statistics and also considered here. Mean is in other words the average value: it’s the sum of values (\\(X\\)) divided by number of values: \\[\\bar{X} = \\frac{1}{N} \\sum{^N_{i=1}}{X_i}\\] A feature of mean value is that if you only know the \\(\\bar{X}\\) and \\(N\\), you can still calculate \\(\\sum{^N_{i=1}}{X_i}\\). 3.2 Variability Central tendency describes values only partially as it tells nothing about the deviation of values from that mean. Estimating also the variability of values provides a more manifold understanding of values. See Navarro and Foxcroft (2018) section 4.2. 3.2.1 Range Most simple way to express variability is to indicate the range of all values, i.e. the minimum and maximum values. 3.2.2 Quantiles and interquartile range Quantiles are in essence calculated just like median, because median is the lowest quantile, the 2-quantile. In addition to dividing sequence of ordered values into two halves separated by median, such sequence can be diveded into any number of equal groups as long as the number of groups (\\(k\\)) is smaller than or equal to the number of values, i.e. \\(k \\le N\\). Some common quantiles are quartiles (\\(k = 4\\)), deciles (\\(k = 10\\)) and centiles/percentiles (\\(k = 100\\)). Arguably quartile is most frequently used among quantiles because the 2nd and 4th quartiles contain half of all values. This interquartile range (IQR) thus contains the middle half of all values. 3.2.3 Variance Although difficult to interpret, variance is used in many statistical calculations due to its mathematical properties. Variance is mean squared difference from the mean value: \\[Var(X) = \\frac{1}{N} \\sum{^N_{i=1}{(X_i-\\bar{X})^2}}\\] 3.2.4 Standard deviation Interpretability issues of variance arise from the fact that the calculation includes squaring and thus the value of the statistic is vastly different to understand regarding initial scale. A solution would be to find a square root of variance. This is what the standard deviation is: the square root of variance. \\[\\sigma = \\sqrt{\\frac{1}{N} \\sum{^N_{i=1}{(X_i-\\bar{X})^2}}}\\] 3.3 Plots Previously explained measures allow us to only summarize values into fewer numbers. Plotting allows to present these values more intuitively or even depict all of the values at once. 3.3.1 Boxplot Boxplots illustrate the quartiles of values (including interquartile range) and extreme values (outliers). Outliers are usually values that are below the 2nd quartile or above the 4th quartile by 1.5 times the interquartile range. On boxplots, half of all the values lie within the box and another half on the lines, outliers excluded. See Navarro and Foxcroft (2018) section 5.2. 3.3.2 Histogram and density plot Histograms are essentially barplots where all values are divided between ranges of equal with, i.e. bins. Instead of bins, distribution of values can also be expressed continuously by smoothing the bins. This results in a density plot. See Navarro and Foxcroft (2018) section 5.1. "],["references.html", "Section 4 References", " Section 4 References Crawley, Michael J. 2013. The r Book. Second edition. Chichester, West Sussex, UK: Wiley. https://www.cs.upc.edu/~robert/teaching/estadistica/TheRBook.pdf. Dash, Ian. 2016. “Flowchart of Statistics for Research.” https://doi.org/10.13140/RG.2.2.12014.41283/1. Navarro, Danielle J, and David R Foxcroft. 2018. Learning Statistics with Jamovi: A Tutorial for Psychology Students and Other Beginners. Danielle J. Navarro; David R. Foxcroft. https://doi.org/10.24384/HGC3-7P15. Stevens, S. S. 1946. “On the Theory of Scales of Measurement.” Science 103 (2684): 677–80. https://doi.org/10.1126/science.103.2684.677. Wickham, Hadley. 2014. “Tidy Data.” Journal of Statistical Software 59 (1): 1–23. https://doi.org/10.18637/jss.v059.i10. "]]
