<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Logistic regression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Jüri Lillemets" />
    <meta name="date" content="2021-05-20" />
    <script src="11_logistic_files/header-attrs-2.8/header-attrs.js"></script>
    <link rel="stylesheet" href="minimal.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Logistic regression
## Research methods
### Jüri Lillemets
### 2021-05-20

---




class: center middle clean

# How to model a binary response variable?

---

class: center middle inverse

# Linear regression with binary response

---

Let's use a data set on spam email.



- `crl.tot` total length of words in capitals
- `dollar` number of occurrences of the "$" symbol
- `bang` number of occurrences of the "!" symbol
- `money` number of occurrences of the word "money"
- `n000` number of occurrences of the string "000"
- `make` number of occurrences of the word "make"
- `yesno` outcome variable, a factor with levels n not spam, y spam

---

Do occurrences of dollar symbol have an effect on categorizing an email as spam? Can we predict spam from dollar signs?

![](11_logistic_files/figure-html/unnamed-chunk-2-1.png)&lt;!-- --&gt;

---

Let's estimate a linear model where response `spam` is predicted from `dollar`.


```
## 
## Call:
## lm(formula = spam ~ dollar, data = Oie)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -1.7187 -0.2903 -0.2903  0.4497  0.7097 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept) 0.290262   0.007034   41.27   &lt;2e-16 ***
## dollar      1.666731   0.048377   34.45   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## Residual standard error: 0.4341 on 4552 degrees of freedom
## Multiple R-squared:  0.2068,	Adjusted R-squared:  0.2067 
## F-statistic:  1187 on 1 and 4552 DF,  p-value: &lt; 2.2e-16
```

---

This is how an ordinary linear model fits.

![](11_logistic_files/figure-html/unnamed-chunk-4-1.png)&lt;!-- --&gt;

&gt; Is this a good fit?

---

What about the assumptions?

![](11_logistic_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

--

&gt; Are the assumptions of normality and constant variance of residuals satisfied?

---

How are the errors distributed?

![](11_logistic_files/figure-html/unnamed-chunk-6-1.png)&lt;!-- --&gt;

--

Assumptions of linear regression model can not be met when response is binary.

---

class: center middle inverse

# Estimation of generalized linear models

---

What to do if the distribution of errors is such that it can not meet assumptions of linear regression?

--

Specify a distribution of errors! For binary data we shoult use binomial distribution.

![](11_logistic_files/figure-html/unnamed-chunk-7-1.png)&lt;!-- --&gt;

---

## Generalized linear models (GLM)

Least squares requires normal distribution of errors. So we can not use this. 

Generalized linear models allow us to specify an error distribution prior to estimation.

--

Generalized linear models can also be used for other than binary response variable, e.g.

- normal data, 
- data with gamma distribution, 
- count data (incl. zero-inflated or zero-truncated response), 
- truncated or censored data.

???

Application of models is creative.

---

Let's estimate the same model now as a generalized linear model.


```
## 
## Call:
## glm(formula = spam ~ dollar, family = binomial(link = "logit"), 
##     data = Oie)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -4.9642  -0.7561  -0.7561   0.6825   1.6684  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.10598    0.03897  -28.38   &lt;2e-16 ***
## dollar      15.66840    0.65343   23.98   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 6083.7  on 4553  degrees of freedom
## Residual deviance: 4758.8  on 4552  degrees of freedom
## AIC: 4762.8
## 
## Number of Fisher Scoring iterations: 6
```

---

## Logit link

Link function relates the mean value of response to predictor variable(s), allowing us to apply a particular distribution of errors.

Link function transforms the mean of response variable.

--

The logit link is mathematically expressed as follows:

`$$ln(\frac{p}{1 - p}) = \alpha + \beta x,$$`

where `\(p\)` is the probability that `\(y = 1\)`.

---

What does the generalized version of the model look like?

![](11_logistic_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

--

&gt; Why is it better than linear model?

---

A better illustration: predict transmission of a car from its weight.

![](11_logistic_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;

---

## Maximum likelihood estimation (MLE)

The parameters of a GLM can not be simply calculated using the least squares method. 

--

Models with various parameters are **iteratively** fitted until we find such parameters for which the data we have is most likely.

In case of OLS: Data -&gt; Parameters  
For MLE: Parameters -&gt; Data

---

### Likelihood

Likelihood expresses how likely is the data we have given the parameters.

It can not be directly interpreted but it is used to calculate measures of model fit.

---

class: center middle inverse

# Interpretation and diagnostics

---

## Coefficients

The coefficient is the increase in logged odds that `\(y = 1\)`.

Recall the logit link `\(ln(\frac{p}{1 - p}) = \alpha + \beta x\)`, where `\(p\)` is the probability that `\(y = 1\)`.

We are estimating log odds ratio: `\(\frac{p}{1-p} = e^{\alpha + \beta x}\)`.

Exponent of a coefficient is thus odds ratio: `\(\frac{p}{1-p} = \frac{p(y = 1)}{(y \neq 1)}\)`.

If odds ratio is 0.5, then a unit increase of predictor **decreases** the odds of `\(y = 1\)` twice. If odds ratio is 2, then a unit increase of predictor **increases** the odds of `\(y = 1\)` twice.

---


```
## 
## Call:
## glm(formula = spam ~ dollar, family = binomial(link = "logit"), 
##     data = Oie)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -4.9642  -0.7561  -0.7561   0.6825   1.6684  
## 
## Coefficients:
##             Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept) -1.10598    0.03897  -28.38   &lt;2e-16 ***
## dollar      15.66840    0.65343   23.98   &lt;2e-16 ***
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 6083.7  on 4553  degrees of freedom
## Residual deviance: 4758.8  on 4552  degrees of freedom
## AIC: 4762.8
## 
## Number of Fisher Scoring iterations: 6
```

--

&gt; Does the number of dollar symbols have an effect of email categorized as spam?

--

&gt; Does an increase in the number of dollar symbols decrease the odds of email categorized as spam?

---

class: middle

.center(![increased_risk](../img/increased_risk.png))

.footnote[Source: XKCD,  
increased risk]

---

## Model fit

### Pseudo `\(R^2\)`

An alternative of `\(R^2\)` for linear regression, although calculation and interpretation is different:

`$$R^2 = 1 - \frac{ln\theta_{reduced}}{ln\theta_{full}},$$`

where `\(\theta_{reduced}\)` is the likelihood of model with only intercept and `\(\theta_{full}\)` likelihood of model with predictors. 

The values lie between 0 and 1 and usually values  `\(&gt;0.4\)` are considered to indicate good fit.

???

How much does the addition of predictors improve the model.

---

### Likelihood ratio test

This test can be used to determine if a complex model is different from a simpler one:

`$$LR = -2ln(\frac{\theta_1}{\theta_2}),$$`

where `\(\theta_1\)` is the likelihood of simpler model and `\(\theta_2\)` the likelihood of complex model. The hypotheses are as follows:

`\(H_0: L_1 = L_2\)`  
`\(H_1: L_1 \neq L_2.\)`

If difference can not be shown, then the simpler model should be preferred. 

---

## Classification

### Probabilities

Fitte values of logistic regression model are `\(p\)`, i.e. the probability that `\(y = 1\)`:

`$$p = \frac{e^{\alpha + \beta x}}{1 + e^{\alpha + \beta x}}$$`

Value of `\(p\)` lies between 0 and 1. 

For classification we thus need to choose a cutoff point.

---

If cutoff point is .5


```
##         Classified
## Observed    0    1
##        0 2541  245
##        1  719 1049
```

If cutoff point is .2


```
##         Classified
## Observed    0    1
##        0 2676  110
##        1  885  883
```

If cutoff point is .1


```
##         Classified
## Observed    0    1
##        0 2718   68
##        1 1049  719
```

---

### Confusion matrix

Classification table or a confusion matrix demonstrates the classification results.


```
##         Classified
## Observed    0    1  Sum
##      0   2676  110 2786
##      1    885  883 1768
##      Sum 3561  993 4554
```

We can calculate various measures from this table:

- accuracy: `\((2676 + 884) / 4554 = 0.78\)`; 
- sensitivity: `\(883 / 993 = 0.89\)`; 
- specifity: `\(2676 / 3561 = 0.75\)`;
- ...

---

class: inverse

???

Illustration of maximizing likelihood. Explanation of odds from a contingency table. ROC and AUC. Deviance and other residuals.

# Labor Force Participation Data. Cross-section data originating from the 1976 Panel Study of Income Dynamics (PSID), based on data for the previous year, 1975.

.small[
- `participation` Factor. Did the individual participate in the labor force in 1975? ...
- `hours` Wife's hours of work in 1975.
- `youngkids` Number of children less than 6 years old in household.
- `oldkids` Number of children between ages 6 and 18 in household.
- `age` Wife's age in years.
- `education` Wife's education in years.
- `wage` Wife's average hourly wage, in 1975 dollars.
- `repwage` Wife's wage reported at the time of the 1976 interview ...
- `hhours` Husband's hours worked in 1975.
- `hage` Husband's age in years.
- `heducation` Husband's education in years.
- `hwage` Husband's wage, in 1975 dollars.
- `fincome` Family income, in 1975 dollars. ...
- `tax` Marginal tax rate facing the wife, ...
- `meducation` Wife's mother's educational attainment, in years.
- `feducation` Wife's father's educational attainment, in years.
- `unemp` Unemployment rate in county of residence, in percentage points. ...
- `city` Factor. Does the individual live in a large city?
- `experience` Actual years of wife's previous labor market experience.
- `college` Factor. Did the individual attend college?
- `hcollege` Factor. Did the individual's husband attend college?
]

# Airbag and other influences on accident fatalities


.small[
- `dvcat` ordered factor with levels (estimated impact speeds) 1-9km/h, 10-24, 25-39, 40-54, 55+
- `weight` Observation weights, albeit of uncertain accuracy, designed to account for varying sampling probabilities.
- `dead` factor with levels alive dead
- `airbag` a factor with levels none airbag
- `seatbelt` a factor with levels none belted
- `frontal` a numeric vector; 0 = non-frontal, 1=frontal impact
- `sex` a factor with levels f m
- `ageOFocc` age of occupant in years
- `yearacc` year of accident
- `yearVeh` Year of model of vehicle; a numeric vector
- `abcat` Did one or more (driver or passenger) airbag(s) deploy? This factor has levels deploy nodeploy unavail
- `occRole` a factor with levels driver pass
- `deploy` a numeric vector: 0 if an airbag was unavailable or did not deploy; 1 if one or more bags deployed.
- `injSeverity` a numeric vector; 0:none, 1:possible injury, 2:no incapacity, 3:incapacity, 4:killed; 5:unknown, 6:prior death
- `caseid` character, created by pasting together the populations sampling unit, the case number, and the vehicle number. Within each year, use this to uniquely identify the vehicle.
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
