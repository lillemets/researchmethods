---
title: Factor analysis
subtitle: Research methods
author: JÃ¼ri Lillemets
date: "`r Sys.Date()`"
output_yaml: _output.yml
editor_options: 
  chunk_output_type: console
---

``` {r setup, include = F}
# Settings
knitr::opts_chunk$set(echo = F, warning = F, message = F, dpi = 200, fig.height = 4)
# Load packages
library('magrittr');library('knitr')
library('DiagrammeR');library('psych')
# Options
options(scipen = F, digits = 3)
# Set colors
Col <- c(red = '#e6457a', green = '#b0e645', blue = '#45cbe6')
```

class: center middle clean

# What are the underlying factors behind variables?

---

class: center middle inverse

# Intuition

---

## Factor analysis (FA) and principal component analysis (PCA)

In PCA we are attempting to maximize the **total variation in data**. In factor analysis we instead try to maximize some **underlying shared variation between variables**.

PCs are uniquely defined while factors depend on estimation and rotation method.

In PCA each PC is a linear combination of variables but in FA the variables are expressed as linear combinations of factors.

---

What loads what?

.pull-left[
``` {r}
grViz(
  "digraph pc {
  rankdir=LR
  graph [fontname = RobotoCondensed, fontsize = 8]
  node [shape = box] x_1; x_2; x_3; x_4; x_5
  node [shape = circle] PC_1; PC_2
  
  {x_1 x_2 x_3 x_4 x_5} -> PC_1
  {x_1 x_2 x_3 x_4 x_5} -> PC_2
  }",
  width = 400, height = 400)
```
]
.pull-right[
``` {r}
grViz(
  "digraph {
  rankdir = LR
  graph [fontname = RobotoCondensed, fontsize = 8]
  node [shape = circle] x_1; x_2; x_3; x_4; x_5
  node [shape = box] F_1; F_2; u_1; u_2; u_3; u_4; u_5
  
  {rank = same x_1; x_2; x_3; x_4; x_5}
  {rank = same u_1; u_2; u_3; u_4; u_5}
  
  F_1 -> {x_1 x_2 x_3 x_4 x_5}
  F_2 -> {x_1 x_2 x_3 x_4 x_5}
  
  x_1 -> u_1 [dir=back]
  u_2 -> x_2
  u_3 -> x_3
  u_4 -> x_4
  u_5 -> x_5
  }", 
  width = 400, heigh = 400)
```
]

---

### Should we use PCA or FA?

If our goal would be to **summarize variables** into a smaller set of variables, then we should use PCA. 

If the goal is to **determine some underlying variables**, then we should use FA.

---

## Orthogonal factor model

The factor model is defined as

$$x_j = q_{jl} F_l + U_j +\mu_j,$$

where 

- $x_j$ is a variable $j$, 
- $q_{jl}$ the loading of the $j$th variable on the $l$th common factor, 
- $F_l$ the $l$th common factor, 
- $U_j$ the $j$th specific factor and 
- $\mu_j$ the mean of $x_j$. 

---

class: center middle inverse

# Estimation

---

## Estimating the model

There are three methods for extracting factors. We are not going to cover the differences but these are:

- minimum residuals, 
- maximum likelihood, and
- principal axis method.

---

Let's use data on 25 personality items of 2800 people.

.compact[
``` {r}
Oie <- psych::bfi
Items <- Oie[, 1:25]
#Oie <- Oie[complete.cases(Items), ]
kable(head(Oie))
```
]

- ...
- `gender` Males = 1, Females = 2
- `education` 1 = HS, 2 = finished HS, 3 = some college, 4 = college graduate 5 = graduate degree
- `age` age in years

---

The item data were collected using a 6 point response scale where 1 is very inaccurate and 6 is very accurate.

.smaller[
- `A1` Am indifferent to the feelings of others. (q_146)
- `A2` Inquire about others' well-being. (q_1162)
- `A3` Know how to comfort others. (q_1206)
- `A4` Love children. (q_1364)
- `A5` Make people feel at ease. (q_1419)
- `C1` Am exacting in my work. (q_124)
- `C2` Continue until everything is perfect. (q_530)
- `C3` Do things according to a plan. (q_619)
- `C4` Do things in a half-way manner. (q_626)
- `C5` Waste my time. (q_1949)
- `E1` Don't talk a lot. (q_712)
- `E2` Find it difficult to approach others. (q_901)
- `E3` Know how to captivate people. (q_1205)
- `E4` Make friends easily. (q_1410)
- `E5` Take charge. (q_1768)
- `N1` Get angry easily. (q_952)
- `N2` Get irritated easily. (q_974)
- `N3` Have frequent mood swings. (q_1099)
- `N4` Often feel blue. (q_1479)
- `N5` Panic easily. (q_1505)
- `O1` Am full of ideas. (q_128)
- `O2` Avoid difficult reading material.(q_316)
- `O3` Carry the conversation to a higher level. (q_492)
- `O4` Spend time reflecting on things. (q_1738)
- `O5` Will not probe deeply into a subject. (q_1964)
]

``` {r}
Names <- c(
  'Am indifferent to the feelings of others',
  "Inquire about others' well-being", 
  'Know how to comfort others', 
  'Love children', 
  'Make people feel at ease', 
  'Am exacting in my work', 
  'Continue until everything is perfect', 
  'Do things according to a plan', 
  'Do things in a half-way manner', 
  'Waste my time', 
  "Don't talk a lot", 
  'Find it difficult to approach others', 
  'Know how to captivate people', 
  'Make friends easily', 
  'Take charge', 
  'Get angry easily', 
  'Get irritated easily', 
  'Have frequent mood swings', 
  'Often feel blue', 
  'Panic easily', 
  'Am full of ideas', 
  'Avoid difficult reading material', 
  'Carry the conversation to a higher level', 
  'Spend time reflecting on things', 
  'Will not probe deeply into a subject'
)
```

???
The first 25 items are organized by five putative factors: Agreeableness, Conscientiousness, Extraversion, Neuroticism, and Opennness.

---

Let's see what are the loadings if we estimate the factor model without rotation.

.compact[
``` {r}
faItems <- fa(Items, nfactors = 5, rotate = 'none')
tabLoadings <- function(x) {
  Tab <- x$loadings %>% as.data.frame.matrix %>% round(2)
  rownames(Tab) <- Names
  Tab[abs(Tab) < .3] <- NA
  Tab
}
tabLoadings(faItems) %>% kable
```
]

---

## Rotations

To better define factors that best separate our variables, we can apply a rotation on factors. 

This results in an adjusted loadings matrix. 

There are several techniques for rotation. 

---

### Varimax

This rotation involves maximizing variances of squared loadings **within factors**. Factors remain **orthogonal**, thus uncorrelated.

.compact[
``` {r}
fa(Items, nfactors = 5, rotate = 'varimax') %>% tabLoadings %>% kable
```
]

---

### Oblimin

This rotation also involves maximization of squared loading variances **within factors** but with possibly **oblique** factors.

.compact[
``` {r}
fa(Items, nfactors = 5, rotate = 'oblimin') %>% tabLoadings %>% kable
```
]

---

### Quartimax

This rotation aims to maximize variances of factor loadings **within variables**. The result is a factor structure in which each variable loads as few factors as possible.

.compact[
``` {r}
fa(Items, nfactors = 5, rotate = 'quartimax') %>% tabLoadings %>% kable
```
]

???

The difference from Varimax rotation is that factors are not necessarily orthogonal but oblique, thus can be correlated. The resulting factors may be more similar to each other than in case of Varimax but the variances of loadings within factors are likely to be higher.

---

How to think about rotations?

``` {r, fig.height = 5}
par(bty = 'n', family = 'RobotoCondensed')
faItems <- fa(Items, nfactors = 5, rotate = 'none')
plot(faItems$loadings, xlim = c(-1,1), ylim = c(-1,1))
abline(v = 0, h = 0, lty = 2)
```

---

## Assumptions

While PCA has essentially no assumptions, FA has a few. 

### Sphericity

**Variables need to be correleated** to a certain extent for us to able to summarize them into a smaller set of factors. Whether or not correlation matrix is statistically significantly different from zero (identity matrix) can be tested with Bartlett's test.

$H_0:$ Correlation matrix is zero
$H_1:$ Correlation matrix is different from zero

If the test returns $p \ge 0.05$, then we should not trust the results of factor analysis.

---

.compact[
``` {r}
cor(Items, use = 'pairwise.complete.obs') %>% round(1) %>% kable
```
]

P-value here is `r cortest.bartlett(cor(Items, use = 'pairwise.complete.obs'), n = nrow(Items))$p.value`.

> Are the correlations significantly different from zero?

---

### Sampling adequacy

In addition to correlations it is necessary that **each factor is not related to only few variables**. We can use Kaiser-Meyer-Olkin (KMO) measure to determine if sum of partial correlations is higher than sum of correlations or not. The value of the measure is interpreted as follows regarding the suitability of FA.

- 0 ... 0.6 - Not suitable
- 6... 0.7 - Suitable
- 0.7 ... 0.9 - Adequate
- 0.9... 1 - Excellent

--

.compact[
``` {r}
KMO(Items)$MSAi %>% round(2) %>% t %>% kable
```
]

> Is a factor analysis with these varables adequate?

---

class: center middle inverse

# Interpretation

---

## Loadings

The interpretation of loadings in FA is similar to PCA. For FA only loadings that are higher than 0.5 should be considered and used for interpretation of factors.

.compact[
``` {r}
faItems <- fa(Items, nfactors = 5, rotate = 'varimax') 
faItems %>% tabLoadings %>% kable
```
]

---

Let's now see the result with interpretations for each factor.

.compact[
``` {r}
Traits <- c('Agreeableness', 'Conscientiousness', 'Extraversion', 
            'Neuroticism', 'Opennness')
Ordering <- c(4, 3, 2, 1, 5)
faItems %>% tabLoadings %>% kable(col.names = Traits[Ordering])
```
]

---

We can visualize the loadings as well.

``` {r}
fa.diagram(faItems)
```

---

And we can add some variables to the visualization.

``` {r}
fa.extend(Oie, 5, ov = 1:25, ev = 26:28) %>% extension.diagram
```

---

## Uniqueness and communality

Uniqueness is a measure of proportion of variation explained by a particular variable and not by factors. Communality is the inverse of this.

.compact[
``` {r}
faItems %>% tabLoadings %>% 
  cbind(Uniq. = faItems$uniquenesses, Comm. = faItems$communalities) %>%
  round(2) %>% 
  kable
```
]

???
Communality is the variation of a variable that is shared with other variables.

---

## Complexity

This can be calculated for each variable. It expresses the number of factors which load the variable.

.compact[
``` {r}
faItems %>% tabLoadings %>% 
  cbind(Comp. = faItems$complexity) %>% round(2) %>% 
  kable
```
]

---

Recall the factor model $x_j = q_{jl} F_l + U_j +\mu_j$.

.compact[
``` {r}
faItems %>% tabLoadings %>% 
  cbind(Uniq. = faItems$uniquenesses, mu = colMeans(Items, na.rm = T)) %>% 
  round(2) %>% 
  kable
```
]

---

## Scores

As for PCA we can calculate a score of each factor for each observation.

``` {r}
cbind(Oie[26:28], faItems$scores) %>% head(10) %>% kable
```

---

Gender

``` {r}
par(bty = 'n', family = 'RobotoCondensed', mar = c(4,4,3,0), 
    mfrow = c(1,5))
for (i in 1:5) {
  boxplot(faItems$scores[, i] ~ Oie$gender == 1, 
          xlab = "Male", ylab = "Factor score", main = Traits[Ordering][i])
}
```

---

Education

``` {r}
par(bty = 'n', family = 'RobotoCondensed', mar = c(4,4,3,0), 
    mfrow = c(1,5))
for (i in 1:5) {
  boxplot(faItems$scores[, i] ~ Oie$education, 
          xlab = "Education", ylab = "Factor score", main = Traits[Ordering][i])
}
```

---

Age

``` {r}
par(bty = 'n', family = 'RobotoCondensed', mar = c(4,4,3,0), 
    mfrow = c(1,5))
for (i in 1:5) {
  plot(faItems$scores[, i] ~ Oie$age, 
          xlab = "Age", ylab = "Factor score", main = Traits[Ordering][i], 
       pch = 20, cex = .01)
}
```

---

class: inverse
