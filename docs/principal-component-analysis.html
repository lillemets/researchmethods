<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Section 13 Principal component analysis | Research methods</title>
  <meta name="description" content="Section 13 Principal component analysis | Research methods course materials" />
  <meta name="generator" content="bookdown 0.22 and GitBook 2.6.7" />

  <meta property="og:title" content="Section 13 Principal component analysis | Research methods" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Section 13 Principal component analysis | Research methods course materials" />
  <meta name="github-repo" content="lillemets/researchmethods" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Section 13 Principal component analysis | Research methods" />
  
  <meta name="twitter:description" content="Section 13 Principal component analysis | Research methods course materials" />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="logistic-regression.html"/>
<link rel="next" href="slides.html"/>
<script src="libs/header-attrs-2.8/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Research methods</a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Syllabus</a>
<ul>
<li class="chapter" data-level="1.1" data-path="index.html"><a href="index.html#teaching"><i class="fa fa-check"></i><b>1.1</b> Teaching</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="index.html"><a href="index.html#schedule"><i class="fa fa-check"></i><b>1.1.1</b> Schedule</a></li>
<li class="chapter" data-level="1.1.2" data-path="index.html"><a href="index.html#aims"><i class="fa fa-check"></i><b>1.1.2</b> Aims</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="index.html"><a href="index.html#scoring"><i class="fa fa-check"></i><b>1.2</b> Scoring</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="index.html"><a href="index.html#feedback-on-reading-material"><i class="fa fa-check"></i><b>1.2.1</b> Feedback on reading material</a></li>
<li class="chapter" data-level="1.2.2" data-path="index.html"><a href="index.html#research-project"><i class="fa fa-check"></i><b>1.2.2</b> Research project</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="index.html"><a href="index.html#topics"><i class="fa fa-check"></i><b>1.3</b> Topics</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a>
<ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#quantitative-methods"><i class="fa fa-check"></i><b>2.1</b> Quantitative methods</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="introduction.html"><a href="introduction.html#quantitative-and-qualitative-methods"><i class="fa fa-check"></i><b>2.1.1</b> Quantitative and qualitative methods</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#statistics"><i class="fa fa-check"></i><b>2.2</b> Statistics</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="introduction.html"><a href="introduction.html#descriptive-and-inferential-statistics"><i class="fa fa-check"></i><b>2.2.1</b> Descriptive and inferential statistics</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction.html"><a href="introduction.html#frequentist-and-bayesian-approach-to-statistics"><i class="fa fa-check"></i><b>2.2.2</b> Frequentist and bayesian approach to statistics</a></li>
<li class="chapter" data-level="2.2.3" data-path="introduction.html"><a href="introduction.html#statistics-and-data-science-machine-learning-artificial-intelligence"><i class="fa fa-check"></i><b>2.2.3</b> Statistics and data science, machine learning, artificial intelligence, …</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#software"><i class="fa fa-check"></i><b>2.3</b> Software</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="introduction.html"><a href="introduction.html#commonly-used-software"><i class="fa fa-check"></i><b>2.3.1</b> Commonly used software</a></li>
<li class="chapter" data-level="2.3.2" data-path="introduction.html"><a href="introduction.html#jamovi"><i class="fa fa-check"></i><b>2.3.2</b> Jamovi</a></li>
<li class="chapter" data-level="2.3.3" data-path="introduction.html"><a href="introduction.html#r-language-and-rstudio"><i class="fa fa-check"></i><b>2.3.3</b> R language and RStudio</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#data-management"><i class="fa fa-check"></i><b>2.4</b> Data management</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="introduction.html"><a href="introduction.html#data-structure"><i class="fa fa-check"></i><b>2.4.1</b> Data structure</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction.html"><a href="introduction.html#scales-of-measurement"><i class="fa fa-check"></i><b>2.4.2</b> Scales of measurement</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html"><i class="fa fa-check"></i><b>3</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#central-tendency"><i class="fa fa-check"></i><b>3.1</b> Central tendency</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#mode"><i class="fa fa-check"></i><b>3.1.1</b> Mode</a></li>
<li class="chapter" data-level="3.1.2" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#median"><i class="fa fa-check"></i><b>3.1.2</b> Median</a></li>
<li class="chapter" data-level="3.1.3" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#mean"><i class="fa fa-check"></i><b>3.1.3</b> Mean</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#variability"><i class="fa fa-check"></i><b>3.2</b> Variability</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#range"><i class="fa fa-check"></i><b>3.2.1</b> Range</a></li>
<li class="chapter" data-level="3.2.2" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#quantiles-and-interquartile-range"><i class="fa fa-check"></i><b>3.2.2</b> Quantiles and interquartile range</a></li>
<li class="chapter" data-level="3.2.3" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#variance"><i class="fa fa-check"></i><b>3.2.3</b> Variance</a></li>
<li class="chapter" data-level="3.2.4" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#standard-deviation"><i class="fa fa-check"></i><b>3.2.4</b> Standard deviation</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#plots"><i class="fa fa-check"></i><b>3.3</b> Plots</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#boxplot"><i class="fa fa-check"></i><b>3.3.1</b> Boxplot</a></li>
<li class="chapter" data-level="3.3.2" data-path="descriptive-statistics-1.html"><a href="descriptive-statistics-1.html#histogram-and-density-plot"><i class="fa fa-check"></i><b>3.3.2</b> Histogram and density plot</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html"><i class="fa fa-check"></i><b>4</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="4.1" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#sample-and-population"><i class="fa fa-check"></i><b>4.1</b> Sample and population</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#sample-population-sampling"><i class="fa fa-check"></i><b>4.1.1</b> Sample, population, sampling</a></li>
<li class="chapter" data-level="4.1.2" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#estimating-population-parameters"><i class="fa fa-check"></i><b>4.1.2</b> Estimating population parameters</a></li>
<li class="chapter" data-level="4.1.3" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#confidence-intervals"><i class="fa fa-check"></i><b>4.1.3</b> Confidence intervals</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#hypothesis-testing-2"><i class="fa fa-check"></i><b>4.2</b> Hypothesis testing</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#null-and-alternative-hypotheses"><i class="fa fa-check"></i><b>4.2.1</b> Null and alternative hypotheses</a></li>
<li class="chapter" data-level="4.2.2" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#types-of-errors"><i class="fa fa-check"></i><b>4.2.2</b> Types of errors</a></li>
<li class="chapter" data-level="4.2.3" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#test-statistic"><i class="fa fa-check"></i><b>4.2.3</b> Test statistic</a></li>
<li class="chapter" data-level="4.2.4" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#p-value"><i class="fa fa-check"></i><b>4.2.4</b> P-value</a></li>
<li class="chapter" data-level="4.2.5" data-path="hypothesis-testing-1.html"><a href="hypothesis-testing-1.html#multiple-comparisons-problem"><i class="fa fa-check"></i><b>4.2.5</b> Multiple comparisons problem</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="comparing-categorical-data.html"><a href="comparing-categorical-data.html"><i class="fa fa-check"></i><b>5</b> Comparing categorical data</a>
<ul>
<li class="chapter" data-level="5.1" data-path="comparing-categorical-data.html"><a href="comparing-categorical-data.html#contingency-tables"><i class="fa fa-check"></i><b>5.1</b> Contingency tables</a></li>
<li class="chapter" data-level="5.2" data-path="comparing-categorical-data.html"><a href="comparing-categorical-data.html#chi2-test"><i class="fa fa-check"></i><b>5.2</b> <span class="math inline">\(\chi^2\)</span>-test</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="comparing-categorical-data.html"><a href="comparing-categorical-data.html#goodness-of-fit-chi2-test"><i class="fa fa-check"></i><b>5.2.1</b> Goodness of fit <span class="math inline">\(\chi^2\)</span>-test</a></li>
<li class="chapter" data-level="5.2.2" data-path="comparing-categorical-data.html"><a href="comparing-categorical-data.html#chi2-test-of-independence"><i class="fa fa-check"></i><b>5.2.2</b> <span class="math inline">\(\chi^2\)</span>-test of independence</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="comparing-categorical-data.html"><a href="comparing-categorical-data.html#degrees-of-freedom"><i class="fa fa-check"></i><b>5.3</b> Degrees of freedom</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html"><i class="fa fa-check"></i><b>6</b> Comparing numerical data</a>
<ul>
<li class="chapter" data-level="6.1" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#one-or-two-samples"><i class="fa fa-check"></i><b>6.1</b> One or two samples</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#one-sample"><i class="fa fa-check"></i><b>6.1.1</b> One sample</a></li>
<li class="chapter" data-level="6.1.2" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#two-samples"><i class="fa fa-check"></i><b>6.1.2</b> Two samples</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#unpaired-or-paired-samples"><i class="fa fa-check"></i><b>6.2</b> Unpaired or paired samples</a></li>
<li class="chapter" data-level="6.3" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#one-tailed-or-two-tailed-tests"><i class="fa fa-check"></i><b>6.3</b> One-tailed or two-tailed tests</a></li>
<li class="chapter" data-level="6.4" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#parametric-or-nonparametric-tests"><i class="fa fa-check"></i><b>6.4</b> Parametric or nonparametric tests</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#normality"><i class="fa fa-check"></i><b>6.4.1</b> Normality</a></li>
<li class="chapter" data-level="6.4.2" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#nonparametric-tests"><i class="fa fa-check"></i><b>6.4.2</b> Nonparametric tests</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="comparing-numerical-data.html"><a href="comparing-numerical-data.html#how-to-decide-which-test-to-use"><i class="fa fa-check"></i><b>6.5</b> How to decide which test to use?</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html"><i class="fa fa-check"></i><b>7</b> Analysis of variance</a>
<ul>
<li class="chapter" data-level="7.1" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#one-way-anova"><i class="fa fa-check"></i><b>7.1</b> One-way Anova</a></li>
<li class="chapter" data-level="7.2" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#post-hoc-tests"><i class="fa fa-check"></i><b>7.2</b> Post-hoc tests</a></li>
<li class="chapter" data-level="7.3" data-path="analysis-of-variance.html"><a href="analysis-of-variance.html#how-to-decide-which-test-to-use-1"><i class="fa fa-check"></i><b>7.3</b> How to decide which test to use?</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="correlation-analysis.html"><a href="correlation-analysis.html"><i class="fa fa-check"></i><b>8</b> Correlation analysis</a>
<ul>
<li class="chapter" data-level="8.1" data-path="correlation-analysis.html"><a href="correlation-analysis.html#scatterplot"><i class="fa fa-check"></i><b>8.1</b> Scatterplot</a></li>
<li class="chapter" data-level="8.2" data-path="correlation-analysis.html"><a href="correlation-analysis.html#pearsons-correlation-coefficient"><i class="fa fa-check"></i><b>8.2</b> Pearson’s correlation coefficient</a></li>
<li class="chapter" data-level="8.3" data-path="correlation-analysis.html"><a href="correlation-analysis.html#spearman-rank-order-correlation-coefficient"><i class="fa fa-check"></i><b>8.3</b> Spearman rank-order correlation coefficient</a></li>
<li class="chapter" data-level="8.4" data-path="correlation-analysis.html"><a href="correlation-analysis.html#correlation-matrix-and-heatmap"><i class="fa fa-check"></i><b>8.4</b> Correlation matrix and heatmap</a></li>
<li class="chapter" data-level="8.5" data-path="correlation-analysis.html"><a href="correlation-analysis.html#causality"><i class="fa fa-check"></i><b>8.5</b> Causality</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html"><i class="fa fa-check"></i><b>9</b> Simple linear regression</a>
<ul>
<li class="chapter" data-level="9.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#ordinary-least-squares"><i class="fa fa-check"></i><b>9.1</b> Ordinary least squares</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#model-specification"><i class="fa fa-check"></i><b>9.1.1</b> Model specification</a></li>
<li class="chapter" data-level="9.1.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#calculation"><i class="fa fa-check"></i><b>9.1.2</b> Calculation</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#elements-of-ols-regression-models"><i class="fa fa-check"></i><b>9.2</b> Elements of (OLS) regression models</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#intercept"><i class="fa fa-check"></i><b>9.2.1</b> Intercept</a></li>
<li class="chapter" data-level="9.2.2" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#coefficients"><i class="fa fa-check"></i><b>9.2.2</b> Coefficient(s)</a></li>
<li class="chapter" data-level="9.2.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#fitted-values"><i class="fa fa-check"></i><b>9.2.3</b> Fitted values</a></li>
<li class="chapter" data-level="9.2.4" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#residuals"><i class="fa fa-check"></i><b>9.2.4</b> Residuals</a></li>
<li class="chapter" data-level="9.2.5" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-r2"><i class="fa fa-check"></i><b>9.2.5</b> The <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="9.2.6" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#the-adjusted--r2"><i class="fa fa-check"></i><b>9.2.6</b> The adjusted- <span class="math inline">\(R^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#assumptions-and-diagnostics"><i class="fa fa-check"></i><b>9.3</b> Assumptions and diagnostics</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="simple-linear-regression.html"><a href="simple-linear-regression.html#gauss-markov-assumptions"><i class="fa fa-check"></i><b>9.3.1</b> Gauss-Markov assumptions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="data-transformations.html"><a href="data-transformations.html"><i class="fa fa-check"></i><b>10</b> Data transformations</a>
<ul>
<li class="chapter" data-level="10.1" data-path="data-transformations.html"><a href="data-transformations.html#log-transformations"><i class="fa fa-check"></i><b>10.1</b> Log-transformations</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="data-transformations.html"><a href="data-transformations.html#log-linear"><i class="fa fa-check"></i><b>10.1.1</b> Log-linear</a></li>
<li class="chapter" data-level="10.1.2" data-path="data-transformations.html"><a href="data-transformations.html#linear-log"><i class="fa fa-check"></i><b>10.1.2</b> Linear-log</a></li>
<li class="chapter" data-level="10.1.3" data-path="data-transformations.html"><a href="data-transformations.html#log-log"><i class="fa fa-check"></i><b>10.1.3</b> Log-log</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="data-transformations.html"><a href="data-transformations.html#polynomials"><i class="fa fa-check"></i><b>10.2</b> Polynomials</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="data-transformations.html"><a href="data-transformations.html#ramsey-reset-test"><i class="fa fa-check"></i><b>10.2.1</b> Ramsey RESET test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Multiple linear regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#multiple-predictors"><i class="fa fa-check"></i><b>11.1</b> Multiple predictors</a></li>
<li class="chapter" data-level="11.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#predictor-selection"><i class="fa fa-check"></i><b>11.2</b> Predictor selection</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#akaike-information-criterion"><i class="fa fa-check"></i><b>11.2.1</b> Akaike information criterion</a></li>
<li class="chapter" data-level="11.2.2" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#model-comparison-with-f-test"><i class="fa fa-check"></i><b>11.2.2</b> Model comparison with F-test</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="multiple-linear-regression.html"><a href="multiple-linear-regression.html#multicollinearity"><i class="fa fa-check"></i><b>11.3</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="logistic-regression.html"><a href="logistic-regression.html"><i class="fa fa-check"></i><b>12</b> Logistic regression</a>
<ul>
<li class="chapter" data-level="12.1" data-path="logistic-regression.html"><a href="logistic-regression.html#generalized-linear-models"><i class="fa fa-check"></i><b>12.1</b> Generalized linear models</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="logistic-regression.html"><a href="logistic-regression.html#logit-link"><i class="fa fa-check"></i><b>12.1.1</b> Logit link</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="logistic-regression.html"><a href="logistic-regression.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>12.2</b> Maximum likelihood estimation</a></li>
<li class="chapter" data-level="12.3" data-path="logistic-regression.html"><a href="logistic-regression.html#interpretation-of-coefficients"><i class="fa fa-check"></i><b>12.3</b> Interpretation of coefficients</a></li>
<li class="chapter" data-level="12.4" data-path="logistic-regression.html"><a href="logistic-regression.html#model-fit"><i class="fa fa-check"></i><b>12.4</b> Model fit</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="logistic-regression.html"><a href="logistic-regression.html#deviance"><i class="fa fa-check"></i><b>12.4.1</b> Deviance</a></li>
<li class="chapter" data-level="12.4.2" data-path="logistic-regression.html"><a href="logistic-regression.html#pseudo-r2"><i class="fa fa-check"></i><b>12.4.2</b> Pseudo <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="12.4.3" data-path="logistic-regression.html"><a href="logistic-regression.html#likelihood-ratio-test"><i class="fa fa-check"></i><b>12.4.3</b> Likelihood ratio test</a></li>
<li class="chapter" data-level="12.4.4" data-path="logistic-regression.html"><a href="logistic-regression.html#overdispersion"><i class="fa fa-check"></i><b>12.4.4</b> Overdispersion</a></li>
<li class="chapter" data-level="12.4.5" data-path="logistic-regression.html"><a href="logistic-regression.html#classification"><i class="fa fa-check"></i><b>12.4.5</b> Classification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html"><i class="fa fa-check"></i><b>13</b> Principal component analysis</a>
<ul>
<li class="chapter" data-level="13.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#intuition"><i class="fa fa-check"></i><b>13.1</b> Intuition</a></li>
<li class="chapter" data-level="13.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#finding-the-pcs"><i class="fa fa-check"></i><b>13.2</b> Finding the PCs</a></li>
<li class="chapter" data-level="13.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#calculation-1"><i class="fa fa-check"></i><b>13.3</b> Calculation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#spectral-decomposition"><i class="fa fa-check"></i><b>13.3.1</b> Spectral decomposition</a></li>
<li class="chapter" data-level="13.3.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#singular-value-decomposition"><i class="fa fa-check"></i><b>13.3.2</b> Singular Value decomposition</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#number-of-components"><i class="fa fa-check"></i><b>13.4</b> Number of components</a></li>
<li class="chapter" data-level="13.5" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#interpretation"><i class="fa fa-check"></i><b>13.5</b> Interpretation</a>
<ul>
<li class="chapter" data-level="13.5.1" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#variation-explained"><i class="fa fa-check"></i><b>13.5.1</b> Variation explained</a></li>
<li class="chapter" data-level="13.5.2" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#loadings"><i class="fa fa-check"></i><b>13.5.2</b> Loadings</a></li>
<li class="chapter" data-level="13.5.3" data-path="principal-component-analysis.html"><a href="principal-component-analysis.html#biplots"><i class="fa fa-check"></i><b>13.5.3</b> Biplots</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="slides.html"><a href="slides.html"><i class="fa fa-check"></i><b>14</b> Slides</a></li>
<li class="chapter" data-level="15" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i><b>15</b> References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Research methods</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="principal-component-analysis" class="section level1" number="13">
<h1><span class="header-section-number">Section 13</span> Principal component analysis</h1>
<p>Principal component analysis (PCA) is a method in the field of multivariate statistics. In such methods we do not define any causality between variables by distinguishing between response and predictor variables. Instead, methods in multivariate statistics look at the overall structure of data and attempt to identify patterns. PCA allows to find such patterns that could be used to reduce the number of variables without losing too much information. This can be useful e.g. when there are a lot of correlated predictors in a regression model.</p>
<p>See <span class="citation"><a href="#ref-crawley_r_2013" role="doc-biblioref">Crawley</a> (<a href="#ref-crawley_r_2013" role="doc-biblioref">2013</a>)</span> section 25.1 and <span class="citation"><a href="#ref-navarro_learning_2018" role="doc-biblioref">Navarro and Foxcroft</a> (<a href="#ref-navarro_learning_2018" role="doc-biblioref">2018</a>)</span> section 15.2.</p>
<div id="intuition" class="section level2" number="13.1">
<h2><span class="header-section-number">13.1</span> Intuition</h2>
<p>The underlying goal of PCA in simple terms is to summarize many variables into one, few or several new variables. More precisely, the aim is to determine a set of standardized linear combinations that would explain a maximum amount of variation in data. Sometimes only one linear combination is found such that it best separates observations. As such, PCA is a dimensionality reduction technique.</p>
<p>Each linear combination that summarizes part of variance in data is called a principal component (PC). These linear combinations <span class="math inline">\(\xi_j\)</span> can be expressed as <span class="math inline">\(\xi_j = b_{j1}x_1 + b_{j2}x_2+ ... a_{jp}x_p\)</span>, where <span class="math inline">\(b_{jp}\)</span> is a weight of variable <span class="math inline">\(x_p\)</span> of a particular <span class="math inline">\(\xi_j\)</span>, i.e. <span class="math inline">\(j\)</span>th PC. PCs are thus essentially weighted sum of variables. The ordering of PCs is fixed: PCs are ordered decreasingly, starting from the PC that explains the most variation in data. The maximum number of PCs we can determine is <span class="math inline">\(min(p, n - 1)\)</span>.</p>
</div>
<div id="finding-the-pcs" class="section level2" number="13.2">
<h2><span class="header-section-number">13.2</span> Finding the PCs</h2>
<p>There are several ways to understand the estimation PCs. An intuitive approach would be to visualize a data cloud from which we incrementally derive the PCs. The first PC should explain the maximum amount of variation in the data cloud. Thus, we choose the first PC1 so that (1) it follows the direction of largest variance in data cloud and (2) is then also a line with smallest orthogonal distance to all data points. As such the idea is similar to least squares estimation, except that in PCA we consider variation in all variables (not just the response) and do not use squared residuals. See the <a href="https://stats.stackexchange.com/questions/2691/making-sense-of-principal-component-analysis-eigenvectors-eigenvalues">relevant question on Stack Exchange</a> for some visual explanations.</p>
<p>Establishing the direction of largest variation requires transforming data points to a new coordinate system. This involves the following steps: (1) centering data points, (2) scaling the axes so that they would be equal, (3) rotating axes into the direction of a PC. In the last step the first PC is rotated so as to maximize variation, whereas each following PC is rotated to be orthogonal to preceding PC.</p>
</div>
<div id="calculation-1" class="section level2" number="13.3">
<h2><span class="header-section-number">13.3</span> Calculation</h2>
<p>Estimation of PCs requires data to be centered, i.e. for each variable <span class="math inline">\(\mu = 0\)</span>. This is usually done by software. Another aspect to consider is scale of data. If software does calculations on correlation matrix then scale is irrelevant because correlation matrix is scale agnostic. However, if covariance matrix is used then variables with higher variance are given more importance (recall that PCA involves maximizing variation). Whether or not this is preferred depends on data and research problem.</p>
<p>In Jamovi: <code>Factor &gt; Principal Component Analysis | Rotation: none</code>.<br />
In R: <code>prcomp(data, scale = TRUE)</code></p>
<p>The transformation of data points into a new coordinate system is done according to the eigenvalues and eigenvectors derived from data. There are two methods for obtaining these: (1) using covariance or correlation matrix of data or (2) using raw values. These methods are described below.</p>
<div id="spectral-decomposition" class="section level3" number="13.3.1">
<h3><span class="header-section-number">13.3.1</span> Spectral decomposition</h3>
<p>A data matrix <span class="math inline">\(X : n \times p\)</span> can be represented by its correlation or covariance matrix <span class="math inline">\(\Sigma\)</span>. This can be decomposed as <span class="math inline">\(\Sigma = V D V^T\)</span>, where <span class="math inline">\(D = diag(\lambda_1, \lambda_2, \dots, \lambda_{n-1})\)</span> is a diagonal matrix of eigenvalues of <span class="math inline">\(\Sigma\)</span> and matrix <span class="math inline">\(V = (v_1, v_2, ..., v_{n-1})\)</span> the corresponding eigenvectors of <span class="math inline">\(\Sigma\)</span>. This can also be expressed as <span class="math display">\[\Sigma w_i = \lambda_i w_i\]</span> where <span class="math inline">\(\lambda_i\)</span> is the eigenvalue that corresponds to eigenvector <span class="math inline">\(w_i\)</span> of <span class="math inline">\(i\)</span>th PC.</p>
</div>
<div id="singular-value-decomposition" class="section level3" number="13.3.2">
<h3><span class="header-section-number">13.3.2</span> Singular Value decomposition</h3>
<p>A data matrix <span class="math inline">\(X : n \times p\)</span> with <span class="math inline">\(rank(X) = k\)</span> can also be decomposed as <span class="math inline">\(X = UDV^T\)</span>, where <span class="math inline">\(U = (u_1, u_2, \dots, u_k)\)</span> is an <span class="math inline">\(n \times n\)</span> vector of eigenvectors of <span class="math inline">\(XX^T\)</span>, <span class="math inline">\(V = (v_1, v_2, ..., v_k)\)</span> is an <span class="math inline">\(p \times p\)</span> vector of eigenvectors of <span class="math inline">\(X^TX\)</span>, and <span class="math inline">\(D = diag(\lambda_1, \lambda_2, \dots, \lambda_k)\)</span> is a diagonal matrix containing nonzero eigenvalues of <span class="math inline">\(X^TX\)</span> and <span class="math inline">\(XX^T\)</span>. Such decomposition of our data matix <span class="math inline">\(X\)</span> then gives us the eigenvalues <span class="math inline">\(\lambda_1, \lambda_2, \dots, \lambda_k\)</span> and corresponding eigenvectors <span class="math inline">\(u_1, u_2, \dots, u_k\)</span> for <span class="math inline">\(X\)</span>.</p>
</div>
</div>
<div id="number-of-components" class="section level2" number="13.4">
<h2><span class="header-section-number">13.4</span> Number of components</h2>
<p>Recall that the aim of PCA is to summarize variables into a smaller number of PCs. The number of PCs that are used is decided by user. Depending on our research problem, we might wish to obtain just one PC or few or more PCs. There also several possible criteria that may help us make the choice:</p>
<ol style="list-style-type: decimal">
<li>choose a threshold of variation in data that PCs should cumulatively explain, e.g. 80%;</li>
<li>use PCs that have eigenvalue above average or above one;</li>
<li>use PCs that are above an “elbow” in scree plot.</li>
</ol>
<p>In Jamovi: <code>Factor &gt; Principal Component Analysis | Scree plot</code>.</p>
</div>
<div id="interpretation" class="section level2" number="13.5">
<h2><span class="header-section-number">13.5</span> Interpretation</h2>
<div id="variation-explained" class="section level3" number="13.5.1">
<h3><span class="header-section-number">13.5.1</span> Variation explained</h3>
<p>The proportion of total variation explained by a <span class="math inline">\(j\)</span>th PC can be found from its eigenvalues: it is the proportion of sums of eigenvalues, i.e. <span class="math inline">\(\lambda_j / \Sigma^p_{j=1} \lambda\)</span>. The proportion of variation explained by first PCs can be found by cumulative sum of the respective values.</p>
<p>This measure illustrates how much information is preserved when summarizing data into a particular number of PCs.</p>
<p>In Jamovi: <code>Factor &gt; Principal Component Analysis | Component summary</code>.<br />
In R: <code>prcomp(data, scale = TRUE)</code></p>
</div>
<div id="loadings" class="section level3" number="13.5.2">
<h3><span class="header-section-number">13.5.2</span> Loadings</h3>
<p>Each PC is defined by the influence that each variable has on it. As such, each variable has a particular loading on each PC which is why the values of this influence are called loadings. Loadings can also be understood as variable weights.</p>
<p>When the linear combinations are calculated for each observation using loadings (weights) and initial variables, we obtain principal component scores. These are in essence the new summarized variables.</p>
<p>Loadings can be used to interpret PCs to give them a theoretical meaning. This is a rather creative process.</p>
<p>In Jamovi: <code>Factor &gt; Principal Component Analysis | Rotation: none &gt; Save | Component scores</code>.<br />
In R: <code>prcomp(data, scale = TRUE)$x</code></p>
</div>
<div id="biplots" class="section level3" number="13.5.3">
<h3><span class="header-section-number">13.5.3</span> Biplots</h3>
<p>These plots concisely summarize the first two PCs by depicting observations on these two dimensions together with loadings of each variable as arrows. Directions of these arrows indicate the direction of loading and length of arrows indicate the magnitude of loading. Then, the angle between arrows represents correlations between variables.</p>
<p>In Jamovi: <code>snowCluster &gt; PCA plot | Biplot</code>.<br />
In R: <code>biplot(prcomp(data, scale = TRUE))</code></p>

</div>
</div>
</div>
<h3> References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-crawley_r_2013" class="csl-entry">
Crawley, Michael J. 2013. <em>The <span>R</span> Book</em>. Second edition. Chichester, West Sussex, UK: Wiley. <a href="https://www.cs.upc.edu/~robert/teaching/estadistica/TheRBook.pdf">https://www.cs.upc.edu/~robert/teaching/estadistica/TheRBook.pdf</a>.
</div>
<div id="ref-navarro_learning_2018" class="csl-entry">
Navarro, Danielle J, and David R Foxcroft. 2018. <em>Learning Statistics with Jamovi: A Tutorial for Psychology Students and Other Beginners</em>. Danielle J. Navarro; David R. Foxcroft. <a href="https://doi.org/10.24384/HGC3-7P15">https://doi.org/10.24384/HGC3-7P15</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="logistic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="slides.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": false,
"twitter": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "section",
"edit": "https://github.com/rstudio/bookdown-demo/edit/master/%s"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
