---
title: Correlation analysis
subtitle: Research methods
author: Jüri Lillemets
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---

``` {r setup, include = F}
# Settings
knitr::opts_chunk$set(echo = F, warning = F, dpi = 150, fig.height = 4)
# Load packages
library('magrittr');library('knitr');library('DiagrammeR')
# Set colors
Col <- c(red = '#e6457a', green = '#b0e645', blue = '#45cbe6')
```

class: center middle clean

# Are two continuous variables related?

---

class: center middle inverse

# Scatterplots

---

Let's look at data on "Speed and Stopping Distances of Cars".

``` {r}
head(cars, 10)
```

---

``` {r, fig.height = 5}
par(bty = 'n', mar = c(4,4,0,0), family = 'RobotoCondensed')
plot(cars, xlab = "Speed, mph", ylab = "Stopping distance, ft")
```

???

Draw lines of possible relationships.

---

class: center middle inverse

# Measures of correlation

---

## Pearson’s correlation coefficient

Evaluates **linear** relationship. Thus, perfect positive correlation implies that when $x$ increases by 1 unit, $y$ also increases by 1 unit.

$$r = \frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}{\sum_{i=1}^{n}(x_i-\bar{x})^2 \sum_{i=1}^{n}(y_i-\bar{y})^2}$$

Essentially, we compare differences from mean value for values of each group.

---

The value of correlation coefficient is between -1 and 1.



---

``` {r, fig.height = 5}
par(bty = 'n', family = 'RobotoCondensed')
plot(cars, xlab = "Speed, mph", ylab = "Stopping distance, ft", 
     main = paste("Pearson's r = ", cor(cars)[2] %>% round(3)))
```

---

## Spearman rank-order correlation coefficient

Evaluation is based on the ranking of values. Evaluates a **monotonic** relationship. Thus perfect positive correlation implies that when $x$ increases, then $y$ also always increases.

$$r = 1 - \frac{6\sum (x_{i}-y_{i})^{2}}{n(n^{2}-1)}$$

Essentially, we compare rankings of values from each group.

---

``` {r, fig.height = 5}
par(bty = 'n', family = 'RobotoCondensed')
plot(cars, xlab = "Speed, mph", ylab = "Stopping distance, ft", 
     main = paste("Pearson's r = ", cor(cars)[2] %>% round(3), "\n", 
                  "Spearman's rho = ", cor(cars, method = 'spearman')[2] %>% round(3)))
```

---

## Linear and monotonic relationships

.pull-left[

Monotonically increasing linear relationship

```{r, fig.height = 7}
par(bty = 'n', family = 'RobotoCondensed')
set.seed(123)
x <- rnorm(100, 100)
y <- x + rnorm(100, 0, .5)
plot(x, y, axes = F, xlab = NA, ylab = NA, cex.main = 2, 
     main = paste(
       "Pearson's r = ", cor(x, y) %>% round(3), "\n", 
       "Spearman's rho = ", cor(x, y, method = 'spearman') %>% round(3)))
```
]

.pull-right[

Monotonically increasing non-linear relationship

```{r, fig.height = 7}
par(bty = 'n', family = 'RobotoCondensed')
set.seed(123)
x <- runif(100, 0, 100)
y <- x^(1/3) + rnorm(100, 0, .5)
plot(x, y, axes = F, xlab = NA, ylab = NA, cex.main = 2, 
     main = paste(
       "Pearson's r = ", cor(x, y) %>% round(3), "\n", 
       "Spearman's rho = ", cor(x, y, method = 'spearman') %>% round(3)))
```
]

---

## Positive and negative relationships

``` {r, fig.height = 4.5}
par(bty = 'n', family = 'RobotoCondensed', mfrow = c(2,3), mar = c(0,0,3,0))
for (i in c(-1, 1)) {
  for (j in c(1, .5, .1)) {
    x <- rnorm(100, 0, 1)
    y <- x * i + rnorm(100, 0, j)
    plot(x, y, axes = F, xlab = NA, ylab = NA, 
         main = paste(
           "Pearson's r = ", cor(x, y) %>% round(3), "\n", 
           "Spearman's rho = ", cor(x, y, method = 'spearman') %>% round(3)))
  }
}
```

---

## Correlation matrix and heatmap

What if we have a lot of variables that we wish to compare to one another?

Correlation matrices and heatmaps can be used to quickly find patterns in data.

---

Let's look at "Swiss Fertility and Socioeconomic Indicators (1888) Data".

``` {r}
names(swiss)[6] <- 'Inf.Mort'
head(swiss)
```

--

### Correlation matrix

``` {r}
cor(swiss) %>% round(3)
```

---

### Heatmap

Heatmap is just the correlation matrix in colors.

.pull-left[
``` {r, fig.height = 7}
par(bty = 'n', family = 'RobotoCondensed')
pheatmap::pheatmap(cor(swiss), cluster_rows = F, cluster_cols = F)
```
]

--

.pull-right[

``` {r, fig.height = 7}
par(bty = 'n', family = 'RobotoCondensed')
pheatmap::pheatmap(cor(swiss))
```
]

---

class: center middle inverse

# Limitations of correlation coefficient

---

## Relationship might not be linear

Correlation coefficient tells us nothing about the shape of an underlying relationship.

---

Anscombe's quartet

``` {r}
Oie <- read.table(header = T, text = '
x1	y1		x2	y2		x3	y3		x4	y4
10	8.04		10	9.14		10	7.46		8	6.58
8	6.95		8	8.14		8	6.77		8	5.76
13	7.58		13	8.74		13	12.74		8	7.71
9	8.81		9	8.77		9	7.11		8	8.84
11	8.33		11	9.26		11	7.81		8	8.47
14	9.96		14	8.1		14	8.84		8	7.04
6	7.24		6	6.13		6	6.08		8	5.25
4	4.26		4	3.1		4	5.39		19	12.5
12	10.84		12	9.13		12	8.15		8	5.56
7	4.82		7	7.26		7	6.42		8	7.91
5	5.68		5	4.74		5	5.73		8	6.89')
```

``` {r}
par(bty = 'n', family = 'RobotoCondensed', mfrow = c(2,2), mar = c(2,2,3,0))
for (i in 1:4) {
  temp <- Oie[, grep(i, names(Oie))]
  plot(temp, 
            main = paste(
              "Pearson's r = ", cor(temp)[2] %>% round(3), "\n", 
              "Spearman's rho = ", cor(temp, method = 'spearman')[2] %>% round(3)))
  abline(0, cor(temp)[2])
}
```

--

This is why you should plot your data!


---

## Causality

.pull-left[
$X$ is correlated to $Y$ , so we might think that $X$ causes $Y$ .

```{r}
grViz("digraph {rankdir=LR; node [shape = circle] X -> Y}", height = 200, width = 400)
```
]

--

.pull-right[
Actually both might be caused by $Z$ , which leads to the correlation between $X$ and $Y$. 
```{r}
grViz("digraph {rankdir=LR; node [shape = circle] X -> Y [dir=none]; Z -> X; Z -> Y}", height = 200, width = 400)
```
]

???
Tell the research about storks and babies.

---

class: middle

.centerg[![](../img/correlation.png)]

.footnote[Source: XKCD, correlation]

---

class: inverse

