---
title: Hypothesis testing<br>Comparing categorical data
subtitle: Research methods
author: JÃ¼ri Lillemets
date: "`r Sys.Date()`"
editor_options: 
  chunk_output_type: console
---

``` {r setup, include = F}
# Settings
knitr::opts_chunk$set(echo = F, dpi = 150, fig.height = 4)
# Load packages
library('magrittr');library('knitr')
```

class: center middle clean

# Is there a difference in frequencies?

---

class: center middle inverse

# Population and sample

---

## But I only have a sample...

When we have data on the entire population we can simply describe it using descriptive statistics. 

But often we only have a part of the population, i.e. a sample.

--

Since we only have data on sample, we can't be sure if same properties hold for population.

Hence, we need to make inferences about the population by estimating population parameters from **random** sample data.

--

We can make inferences with a particular certainty, i.e. confidence interval or error ratio.


???

Sample must be taken from the population *randomly*. For this, every value in the population must have an equal chance of being in sample.

---

## Population mean and standard deviation

Our best estimate of population mean is sample mean, i.e. 

$$\hat{\mu} = \bar{x}.$$

--

However, population standard error estimate needs to be corrected for bias as follows:

$$\hat{\sigma} = \sqrt{\frac{1}{n-1} \sum{^n_{i=1}{(x_i-\bar{x})^2}}}.$$

???

For small $n$, SD is biased towards lower values, we need to "inflate" it.

---

## Confidence interval of the mean

We assume that our sample data comes from normally distributed population data.

Then 95% confidence interval (CI) of the mean can be found as follows:

$$CI_{95} = \hat{x} \pm(1.96\times\frac{\sigma}{\sqrt{N}}).$$

--

$CI_{95}$ **does not** indicate a 95% probability that true mean lies within the CI!

???

No intuitive interpretation. It means that 95% of samples contain the true mean. It just means that we're pretty sure that population mean is within the CI.

---

### Why 1.96 for 95% CI?

For normally distributed standardized data, we expect 95% of values to lie no further than 1.96 units from the mean.

``` {r}
curve(dnorm(x, 0, 1), -3, 3, xlab = "Values", ylab = "Probability")
abline(v = c(-qnorm(.975), qnorm(.975)), col = 'deeppink')
```

???

If distribution was not symmetric we would have different intervals. Data is not standardized, hence the multiplication with SD.

---

class: center middle inverse

# Statistical hypothesis testing

---

## Why statistical hypothesis testing?

Is the color of M&Ms in a bag random? Let's look at 30 bags of M&Ms.

--

```{r, fig.height = 3}
mm <- read.csv('/home/jrl/work/resmeth/docs/data/mm.csv')
plotMm <- function(x){
  barplot(unlist(mm[x, 2:7]), xaxt = 'n', main = x, col = names(mm[, 2:7]))
}
par(mfrow = c(3,10), mar = rep(1,4))
sapply(1:nrow(mm), plotMm) %>% invisible
```

???
Silly example but there's an application in agri-food business.

---

If these were the observed frequencies, we could say that frequencies are different.

```{r}
plotMm(23)
```

---

However, here we can't be so sure.

```{r}
plotMm(19)
```

---

## What about sample and population?

Does our sample of observed values come from the population represented by expected values? 

```{r}
par(mfrow = 1:2, mar = rep(2,4))
plotMm(19)
barplot(sum(mm[19, 2:7])/6 %>% rep(6), main = "Expected", 
        ylim = c(0,12), col = names(mm[, 2:7]), xaxt = 'n')
```

---

class: center middle inverse

#  Comparing categorical data

---

## Goodness of fit $\chi^2$-test

We wish to know if the frequencies of categories are different from expected values.

Observed frequencies in bag 19:

``` {r}
kable(mm[19, 2:7])
```

Expected frequencies if we expect an equal number of all colors:

``` {r}
kable(sum(mm[19, 2:7])/6 %>% rep(6) %>% t, col.names = names(mm[, 2:7]))
```

???
Also empirical and theoretical. We can also choose different expected values.

---

## Test statistic

The value of a test statistic indicates how extreme the differences are.

The test statistic for goodness of fit $\chi^2$-test is calculated as

$$\chi^2 = \sum{^k_{i=1}{\frac{(O_i-E_i)^2}{E_i}}}$$

--

``` {r}
test <- chisq.test(mm[19, 2:7])
obs <- test$observed
exp <- test$expected
```

``` {r, echo = T, results = 'hold'}
obs
exp
sum((obs - exp)^2 / exp)
```

???
The higher the differences, the higher the test statistic.

---

## P-value

This is the probability that a sample value (e.g. the difference) is equal to or more extreme than true value if null hypothesis is true.

Thus, it's the rate of committing a type I error, i.e. the significance level $\alpha$. 

For testing we set a threshold for p-value **beforehand**, conventionally 0.05.

Conventionally, $\alpha = 0.05$. So we accept the rate of committing a type I error of 5%.

???
Why set p-value beforehand. We need to make some concessions, hence need to accept error.

---

P-value for $\chi^2$ = `r test$statistic` on `r test$parameter` DoF is `r test$p.value`. Why?

``` {r}
par(mar = c(4,4,0,0))
curve(dchisq(x, test$parameter), 0, 10, 
      xlab = "Test statistic (chi-squared)", ylab = "Probability")
abline(v = test$statistic, lwd = 2, col = 'cyan') # Our result
abline(v = test$statistic, lwd = 2, col = 'cyan') # Needed
abline(v =qchisq(.95, test$statistic), lwd = 1, col = 'deeppink')
```

---

## Hypotheses

We posit two hypotheses:

$H_0$: There **is no** statistically significant difference.<br>
$H_1$: There **is** a statistically significant difference.

We only test null hypothesis, $H_0$. When we can not confirm $H_0$, we accept the alternative hypothesis, $H_1$.

Suppose that $\alpha = 0.05$. If p-value is $\ge 0.05$, we accept $H_0$. If p-value is $\lt 0.05$, we reject $H_{0}$ and accept $H_1$.

P-value is **not** the probability of $H_0$ being false or $H_1$ being true!

---

Hypotheses for for goodness of fit $\chi^2$-test:

$H_0$: Frequencies of categories are as expected.<br>
$H_1$: Frequencies of categories are different from what is expected.

---

class: center middle

Our p-value is `r test$p.value` and $\alpha = 0.05$.

## Are the frequencies of M&M colors in bag 19 random?

???

NHST. Theoretically, the value of p-value itself is not important.

---

##  $\chi^2$-test of independence

This is done as in previous example, except that we now sum both row and column differences:

$$\chi^2 = \sum{^r_{i=1}\sum{^c_{j=1}}{\frac{(O_{ij}-E_{ij})^2}{E_{ij}}}}.$$

Hypotheses for $\chi^2$-test of independence:

$H_0$: Variables are independent.<br>
$H_1$: Variables are associated.

---

class: inverse
